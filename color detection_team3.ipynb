{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A Group 3\n",
    "\n",
    "Performing the following reactive behaviors.\n",
    "\n",
    "- Exploration  -> Explores the colors around\n",
    "- Love -> Moving Forward (Blue)\n",
    "- Fear -> Moving back (Yellow))\n",
    "- Aggression -> Moving forward with speed (Red)\n",
    "- Curious -> Move around the object (Green)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use traitlets and widgets to display the image in Jupyter Notebook\n",
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import operator\n",
    "#use opencv to covert the depth image to RGB image for displaying purpose\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#using realsense to capture the color and depth image\n",
    "import pyrealsense2 as rs\n",
    "from RobotClass import Robot\n",
    "#multi-threading is used to capture the image in real time performance\n",
    "import threading\n",
    "\n",
    "#initialize the Robot class\n",
    "robot = Robot()\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    \n",
    "    #this changing of this value will be captured by traitlets\n",
    "    color_value = traitlets.Any()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "        \n",
    "        #configure the color and depth sensor\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.configuration = rs.config()  \n",
    "        \n",
    "        #set resolution for the color camera\n",
    "        self.color_width = 640\n",
    "        self.color_height = 480\n",
    "        self.color_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.color, self.color_width, self.color_height, rs.format.bgr8, self.color_fps)\n",
    "\n",
    "        #set resolution for the depth camera\n",
    "        self.depth_width = 640\n",
    "        self.depth_height = 480\n",
    "        self.depth_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.depth, self.depth_width, self.depth_height, rs.format.z16, self.depth_fps)\n",
    "        # Distance\n",
    "        self.dist = 500\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "        \n",
    "        #start the RGBD sensor\n",
    "        self.pipeline.start(self.configuration)\n",
    "        self.pipeline_started = True\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "\n",
    "        #start capture the first color image\n",
    "        color_frame = frames.get_color_frame()   \n",
    "        image = np.asanyarray(color_frame.get_data())\n",
    "        self.color_value = image\n",
    "\n",
    "        #start capture the first depth image\n",
    "        depth_frame = frames.get_depth_frame()           \n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        self.depth_value = depth_colormap \n",
    "        \n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            frames = self.pipeline.wait_for_frames() #receive data from RGBD sensor\n",
    "            \n",
    "            color_frame = frames.get_color_frame() #get the color image\n",
    "            image = np.asanyarray(color_frame.get_data()) #convert color image to numpy array\n",
    "            self.color_value = image #assign the numpy array image to the color_value variable \n",
    "\n",
    "            depth_frame = frames.get_depth_frame() #get the depth image           \n",
    "            depth_image = np.asanyarray(depth_frame.get_data()) #convert depth data to numpy array\n",
    "                \n",
    "            #we only consider the central area of the vision sensor\n",
    "            depth_image[:190,:]=0\n",
    "            depth_image[290:,:]=0\n",
    "            depth_image[:,:160]=0\n",
    "            depth_image[:,480:]=0\n",
    "\n",
    "\n",
    "            \n",
    "            #For object avoidance, we don't consider the distance that are lower than 100mm or bigger than 1000mm\n",
    "            depth_image[depth_image<100]=0\n",
    "            depth_image[depth_image>1000]=0\n",
    "            \n",
    "            #If all of the values in the depth image is 0, the depth[depth!=0] command will fail\n",
    "            #we set a specific value here to prevent this failure\n",
    "            depth_image[0,0]=2000\n",
    "            \n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            self.distance = depth_image[depth_image!=0].min()\n",
    "            if (depth_image[depth_image!=0].min()<500):\n",
    "                cv2.putText(self.color_value, 'Avoiding collision!!!', (320,240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                self.warning_flag=1\n",
    "                print('Avoiding collision!!!')\n",
    "                for j in range(0,9):\n",
    "                    robot.backward(0.3)\n",
    "                for j in range(0,9):\n",
    "                    robot.right(0.5)\n",
    "                \n",
    "            else:\n",
    "                self.warning_flag=0\n",
    "            self.depth_value = depth_colormap   \n",
    "    \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc857d434ff4635993c0d999cfb4532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', width='45%'), Image(value=b'', format='jpeg', width='45%')), laâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "from RobotClass import Robot\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "camera.start() # start capturing the data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialize the Robot class\n",
    "robot = Robot()\n",
    "\n",
    "\n",
    "#create widgets for the displaying of the image\n",
    "display_color = widgets.Image(format='jpeg', width='45%') #determine the width of the color image\n",
    "display_depth = widgets.Image(format='jpeg', width='45%')  #determine the width of the depth image\n",
    "layout=widgets.Layout(width='100%')\n",
    "\n",
    "sidebyside = widgets.HBox([display_color, display_depth],layout=layout) #horizontal \n",
    "display(sidebyside) #display the widget\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def operation(result_colour,res,robot):\n",
    "    if result_colour[res]!=0:\n",
    "            # Checks if max color is red\n",
    "            if res=='r':\n",
    "                # Performs action for detecting red color\n",
    "                print('back forth')\n",
    "                for i in range(0,2):\n",
    "                    for j in range(0,9000):\n",
    "                        robot.set_motors(-(0.5/3),-0.5,-(0.5)/3,-0.5)\n",
    "                    for j in range(0,3000):\n",
    "                        robot.set_motors(0.5,0.5,0.5,0.5)\n",
    "            # Checks if max color is blue\n",
    "            elif res =='b':\n",
    "                # Performs action for detecting blue color\n",
    "                print('blue forward')\n",
    "                for i in range(0,27):\n",
    "                    robot.set_motors(0.3,0.3,0.3,0.3)\n",
    "                for i in range(0,18):\n",
    "                    robot.set_motors(0,0,0,0)\n",
    "            # Checks if max color is yellow\n",
    "            elif res=='y':\n",
    "                # Performs action for detecting yellow color\n",
    "                print('zigzag')\n",
    "                for i in range(0,2):\n",
    "                    for j in range(0,1998):\n",
    "                        robot.set_motors(-0.5,-(0.5/3),-0.5,-(0.5/3))\n",
    "                    for j in range(0,1998):\n",
    "                        robot.set_motors(-(0.5/3),-0.5,-(0.5)/3,-0.5)\n",
    "            # Checks if max color is green\n",
    "            elif res=='g':\n",
    "                # Performs action for detecting green color\n",
    "                print('Rotate')\n",
    "                for j in range(0,18000):\n",
    "                    robot.set_motors(-1, 1,-1,1)\n",
    "    else:\n",
    "        # Makes the robot go forward.\n",
    "        print('Move forward!!!!!')\n",
    "        for j in range(0,18):\n",
    "            robot.set_motors(0.3,0.3,0.3,0.3)\n",
    "\n",
    "#callback function, invoked when traitlets detects the changing of the color image\n",
    "def process(change):\n",
    "    camera.color_value[:140,:]=0\n",
    "    if camera.distance<=800:\n",
    "        print('Detected!!')\n",
    "        image = change['new'] #retrieve data from the input dict2000/9\n",
    "        # To show the bottom of the image.\n",
    "\n",
    "        \n",
    "        frame = cv2.GaussianBlur(camera.color_value, (5, 5), 0)\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        #         hsv = cv2.cvtColor(camera.color_value, cv2.COLOR_BGR2HSV)\n",
    "        result_colour = {}\n",
    "        result_col = {}\n",
    "        # Lower and upper threshold for red color [2]\n",
    "        lower_red = np.array ([160,50,50])\n",
    "        upper_red = np.array([180,255,255])\n",
    "        kernel = np.ones((5,5),'uint8')\n",
    " \n",
    "        mask0 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        # Mask for filtering red\n",
    "        mask = cv2.erode(mask0, None, iterations=2)\n",
    "        red_mask = cv2.GaussianBlur(mask, (3, 3), 0)\n",
    " \n",
    "        result_red = cv2.bitwise_and(camera.color_value, camera.color_value, mask = red_mask)\n",
    "        # Store the max value for red.\n",
    "        result_colour['r'] = np.count_nonzero(result_red)\n",
    "        result_col['r'] = result_red\n",
    "\n",
    "        # Define the lower and upper threshold for yellow [3]\n",
    "        lower_yellow = np.array([22, 93, 0], dtype=\"uint8\")\n",
    "        upper_yellow = np.array([45, 255, 255], dtype=\"uint8\")\n",
    "        \n",
    "        # Mask for filtering yellow\n",
    "        mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "        result_yellow = cv2.bitwise_and(camera.color_value, camera.color_value, mask = mask_yellow)\n",
    "        \n",
    "        # Store the max value for yellow\n",
    "        result_colour['y'] = np.count_nonzero(result_yellow)\n",
    "        result_col['y'] = result_yellow\n",
    "\n",
    "        \n",
    "        # Define the lower and upper threshold for blue[5]\n",
    "        lower_blue = np.array([100,150,0],np.uint8)# [180,255,255]\n",
    "        upper_blue = np.array([140,255,255],np.uint8)\n",
    "        \n",
    "        # Mask for filtering blue\n",
    "        mask2 = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "        result_blue = cv2.bitwise_and(camera.color_value, camera.color_value, mask = mask2)\n",
    "        \n",
    "        # Store the max value for blue\n",
    "        result_colour['b'] = np.count_nonzero(result_blue)\n",
    "        result_col['b'] = result_blue\n",
    "        \n",
    "\n",
    "        # Define the lower and upper threshold for green.[4]\n",
    "        lower_green = np.array ([40, 40,40])\n",
    "        upper_green = np.array([70, 255,255])\n",
    "        kernel = np.ones((5,5),'uint8')\n",
    "        \n",
    "        # Mask for filtering green.\n",
    "        mask0 = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "  \n",
    "\n",
    "        result_green = cv2.bitwise_and(camera.color_value, camera.color_value, mask = mask0)\n",
    "        # Store the max value for green.\n",
    "        result_colour['g'] = np.count_nonzero(result_green)\n",
    "        result_col['g'] = result_green\n",
    "        \n",
    "        print('Dict:::',result_colour)\n",
    "        res = max(result_colour.items(), key=operator.itemgetter(1))[0]\n",
    "        # Calculates the max out of red , green, yellow and blue.\n",
    "        print('check:::',[res,result_colour[res]])\n",
    "        # Creates a thread for running the operations.\n",
    "        t1 = threading.Thread(target=operation,args=(result_colour,res,robot))\n",
    "        t1.start()\n",
    "        t1.join()\n",
    "        display_color.value = bgr8_to_jpeg(cv2.resize(camera.color_value,(320,240)))\n",
    "        display_depth.value = bgr8_to_jpeg(cv2.resize(result_col[res],(320,240)))\n",
    "        cv2.putText(camera.color_value, res, (320,240), cv2.FONT_HERSHEY_SIMPLEX, 10, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        robot.set_motors(0.3,0.3,0.3,0.3)\n",
    "        time.sleep(0.5)\n",
    "        display_color.value = bgr8_to_jpeg(cv2.resize(camera.color_value,(320,240)))\n",
    "\n",
    "#the camera.observe function will monitor the color_value variable. If this value changes, the processing function will be excuted.\n",
    "camera.observe(process, names='color_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict::: {'r': 12178, 'y': 9093, 'b': 31007, 'g': 25704}\n",
      "check::: ['b', 31007]\n",
      "blue forward\n",
      "Detected!!\n",
      "Dict::: {'r': 14977, 'y': 7288, 'b': 29198, 'g': 23202}\n",
      "check::: ['b', 29198]\n",
      "blue forward\n",
      "Detected!!\n",
      "Dict::: {'r': 19875, 'y': 2898, 'b': 28706, 'g': 22197}\n",
      "check::: ['b', 28706]\n",
      "blue forward\n"
     ]
    }
   ],
   "source": [
    "camera.unobserve_all()\n",
    "camera.stop()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [1]NVIDIAâ€™s jetbot project website: https://github.com/NVIDIA-AI-IOT/jetbot\n",
    "\n",
    "\n",
    "- [2]https://stackoverflow.com/questions/38877102/how-to-detect-red-color-in-opencv-python\n",
    "\n",
    "\n",
    "- [3]https://stackoverflow.com/questions/57262974/tracking-yellow-color-object-with-opencv-python\n",
    "\n",
    "\n",
    "- [4]https://stackoverflow.com/questions/47483951/how-to-define-a-threshold-value-to-detect-only-green-colour-objects-in-an-image\n",
    "\n",
    "\n",
    "- [5]https://stackoverflow.com/questions/17878254/opencv-python-cant-detect-blue-objects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
